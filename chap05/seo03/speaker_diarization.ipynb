{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c96c3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyannote.audio in c:\\code\\agent2025\\venv\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: asteroid-filterbanks>=0.4 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (0.4.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (0.33.1)\n",
      "Requirement already satisfied: lightning>=2.0.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (2.5.2)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (2.3.0)\n",
      "Requirement already satisfied: pyannote.core>=5.0.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (5.0.0)\n",
      "Requirement already satisfied: pyannote.database>=5.0.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (5.1.3)\n",
      "Requirement already satisfied: pyannote.metrics>=3.2 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (3.2.1)\n",
      "Requirement already satisfied: pyannote.pipeline>=3.0.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (3.0.1)\n",
      "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (2.8.1)\n",
      "Requirement already satisfied: rich>=12.0.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (14.0.0)\n",
      "Requirement already satisfied: semver>=3.0.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (3.0.4)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (0.13.1)\n",
      "Requirement already satisfied: speechbrain>=1.0.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (1.0.3)\n",
      "Requirement already satisfied: tensorboardX>=2.6 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (2.6.4)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (2.7.1)\n",
      "Requirement already satisfied: torch-audiomentations>=0.11.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (0.12.0)\n",
      "Requirement already satisfied: torchaudio>=2.2.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (2.7.1)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.audio) (1.7.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\code\\agent2025\\venv\\lib\\site-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (6.0.2)\n",
      "Requirement already satisfied: numpy in c:\\code\\agent2025\\venv\\lib\\site-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (1.26.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\code\\agent2025\\venv\\lib\\site-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (4.14.0)\n",
      "Requirement already satisfied: filelock in c:\\code\\agent2025\\venv\\lib\\site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\code\\agent2025\\venv\\lib\\site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (25.0)\n",
      "Requirement already satisfied: requests in c:\\code\\agent2025\\venv\\lib\\site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.67.1)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (0.14.3)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\code\\agent2025\\venv\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (2.5.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.12.13)\n",
      "Requirement already satisfied: setuptools in c:\\code\\agent2025\\venv\\lib\\site-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio) (65.5.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\code\\agent2025\\venv\\lib\\site-packages (from torch>=2.0.0->pyannote.audio) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\code\\agent2025\\venv\\lib\\site-packages (from torch>=2.0.0->pyannote.audio) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\code\\agent2025\\venv\\lib\\site-packages (from torch>=2.0.0->pyannote.audio) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\code\\agent2025\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.13.0->pyannote.audio) (0.4.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\code\\agent2025\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\code\\agent2025\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.6.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.10)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.16.0)\n",
      "Requirement already satisfied: pandas>=0.19 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.3.0)\n",
      "Requirement already satisfied: typer>=0.12.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.7.0)\n",
      "Requirement already satisfied: docopt>=0.6.2 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.6.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\code\\agent2025\\venv\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\code\\agent2025\\venv\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.2.3)\n",
      "Requirement already satisfied: optuna>=3.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from pyannote.pipeline>=3.0.1->pyannote.audio) (4.4.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.16.2)\n",
      "Requirement already satisfied: colorlog in c:\\code\\agent2025\\venv\\lib\\site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\code\\agent2025\\venv\\lib\\site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.41)\n",
      "Requirement already satisfied: Mako in c:\\code\\agent2025\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.3.10)\n",
      "Requirement already satisfied: six>=1.5 in c:\\code\\agent2025\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from rich>=12.0.0->pyannote.audio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from soundfile>=0.12.1->pyannote.audio) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\code\\agent2025\\venv\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n",
      "Requirement already satisfied: hyperpyyaml in c:\\code\\agent2025\\venv\\lib\\site-packages (from speechbrain>=1.0.0->pyannote.audio) (1.2.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\code\\agent2025\\venv\\lib\\site-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->pyannote.audio) (1.3.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\code\\agent2025\\venv\\lib\\site-packages (from tensorboardX>=2.6->pyannote.audio) (6.31.1)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in c:\\code\\agent2025\\venv\\lib\\site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.2.7)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in c:\\code\\agent2025\\venv\\lib\\site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (1.2.5)\n",
      "Requirement already satisfied: primePy>=1.3 in c:\\code\\agent2025\\venv\\lib\\site-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio) (1.3)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in c:\\code\\agent2025\\venv\\lib\\site-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.18.14)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\code\\agent2025\\venv\\lib\\site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.2.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\code\\agent2025\\venv\\lib\\site-packages (from jinja2->torch>=2.0.0->pyannote.audio) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\code\\agent2025\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\code\\agent2025\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\code\\agent2025\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy==1.26 in c:\\code\\agent2025\\venv\\lib\\site-packages (1.26.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyannote.audio\n",
    "%pip install numpy==1.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1106cd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\code\\AGENT2025\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Python311\\Lib\\inspect.py:988: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "  \"pyannote/speaker-diarization-3.1\",\n",
    "  use_auth_token=\"hf_token\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1560ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변경된 작업 디렉토리: C:\\code\\AGENT2025\\chap05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\code\\AGENT2025\\venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "c:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m변경된 작업 디렉토리:\u001b[39m\u001b[33m\"\u001b[39m, os.getcwd())\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 이제 상대 경로 사용 가능\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m diarization = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./audio/싼기타_비싼기타.mp3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m./audio/싼기타_비싼기타.rttm\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m rttm:\n\u001b[32m     13\u001b[39m     diarization.write_rttm(rttm)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\pyannote\\audio\\core\\pipeline.py:327\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, file, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpreprocessors\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    325\u001b[39m     file = ProtocolFile(file, lazy=\u001b[38;5;28mself\u001b[39m.preprocessors)\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_diarization.py:523\u001b[39m, in \u001b[36mSpeakerDiarization.apply\u001b[39m\u001b[34m(self, file, num_speakers, min_speakers, max_speakers, return_embeddings, hook)\u001b[39m\n\u001b[32m    520\u001b[39m     embeddings = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbinarized_segmentations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_overlap\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_exclude_overlap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    529\u001b[39m     hook(\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m, embeddings)\n\u001b[32m    530\u001b[39m     \u001b[38;5;66;03m#   shape: (num_chunks, local_num_speakers, dimension)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_diarization.py:348\u001b[39m, in \u001b[36mSpeakerDiarization.get_embeddings\u001b[39m\u001b[34m(self, file, binary_segmentations, exclude_overlap, hook)\u001b[39m\n\u001b[32m    345\u001b[39m mask_batch = torch.vstack(masks)\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# (batch_size, num_frames) torch.Tensor\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m embedding_batch: np.ndarray = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwaveform_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask_batch\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# (batch_size, dimension) np.ndarray\u001b[39;00m\n\u001b[32m    353\u001b[39m embedding_batches.append(embedding_batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_verification.py:702\u001b[39m, in \u001b[36mPyannoteAudioPretrainedSpeakerEmbedding.__call__\u001b[39m\u001b[34m(self, waveforms, masks)\u001b[39m\n\u001b[32m    700\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m warnings.catch_warnings():\n\u001b[32m    701\u001b[39m             warnings.simplefilter(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m702\u001b[39m             embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m                \u001b[49m\u001b[43mwaveforms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings.cpu().numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\pyannote\\audio\\models\\embedding\\wespeaker\\__init__.py:343\u001b[39m, in \u001b[36mBaseWeSpeakerResNet.forward\u001b[39m\u001b[34m(self, waveforms, weights)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Extract speaker embeddings\u001b[39;00m\n\u001b[32m    328\u001b[39m \n\u001b[32m    329\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    339\u001b[39m \u001b[33;03m    Batch of embeddings.\u001b[39;00m\n\u001b[32m    340\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    342\u001b[39m fbank = \u001b[38;5;28mself\u001b[39m.compute_fbank(waveforms)\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfbank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\pyannote\\audio\\models\\embedding\\wespeaker\\resnet.py:418\u001b[39m, in \u001b[36mResNet.forward\u001b[39m\u001b[34m(self, fbank, weights)\u001b[39m\n\u001b[32m    416\u001b[39m out = \u001b[38;5;28mself\u001b[39m.layer1(out)\n\u001b[32m    417\u001b[39m out = \u001b[38;5;28mself\u001b[39m.layer2(out)\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m out = \u001b[38;5;28mself\u001b[39m.layer4(out)\n\u001b[32m    421\u001b[39m stats = \u001b[38;5;28mself\u001b[39m.pool(out, weights=weights)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\pyannote\\audio\\models\\embedding\\wespeaker\\resnet.py:142\u001b[39m, in \u001b[36mBasicBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    141\u001b[39m     out = F.relu(\u001b[38;5;28mself\u001b[39m.bn1(\u001b[38;5;28mself\u001b[39m.conv1(x)))\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.bn2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    143\u001b[39m     out += \u001b[38;5;28mself\u001b[39m.shortcut(x)\n\u001b[32m    144\u001b[39m     out = F.relu(out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\code\\AGENT2025\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 작업 디렉토리를 노트북 파일이 있는 위치로 변경\n",
    "os.chdir(r\"C:\\code\\AGENT2025\\chap05\")\n",
    "\n",
    "# 현재 위치 확인\n",
    "print(\"변경된 작업 디렉토리:\", os.getcwd())\n",
    "\n",
    "# 이제 상대 경로 사용 가능\n",
    "diarization = pipeline(\"./audio/싼기타_비싼기타.mp3\")\n",
    "\n",
    "with open(\"./audio/싼기타_비싼기타.rttm\", \"w\", encoding='utf-8') as rttm:\n",
    "    diarization.write_rttm(rttm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c1f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>file</th>\n",
       "      <th>chnl</th>\n",
       "      <th>start</th>\n",
       "      <th>duration</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993</td>\n",
       "      <td>5.805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>7.405</td>\n",
       "      <td>3.983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>11.759</td>\n",
       "      <td>4.927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>17.210</td>\n",
       "      <td>10.665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>28.668</td>\n",
       "      <td>1.536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>414.481</td>\n",
       "      <td>2.970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>417.755</td>\n",
       "      <td>3.476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>423.644</td>\n",
       "      <td>0.776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>424.741</td>\n",
       "      <td>3.527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>428.504</td>\n",
       "      <td>0.844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       type      file  chnl    start  duration  C1  C2  speaker_id  C3  C4\n",
       "0   SPEAKER  싼기타_비싼기타     1    0.993     5.805 NaN NaN  SPEAKER_01 NaN NaN\n",
       "1   SPEAKER  싼기타_비싼기타     1    7.405     3.983 NaN NaN  SPEAKER_01 NaN NaN\n",
       "2   SPEAKER  싼기타_비싼기타     1   11.759     4.927 NaN NaN  SPEAKER_01 NaN NaN\n",
       "3   SPEAKER  싼기타_비싼기타     1   17.210    10.665 NaN NaN  SPEAKER_01 NaN NaN\n",
       "4   SPEAKER  싼기타_비싼기타     1   28.668     1.536 NaN NaN  SPEAKER_01 NaN NaN\n",
       "..      ...       ...   ...      ...       ...  ..  ..         ...  ..  ..\n",
       "83  SPEAKER  싼기타_비싼기타     1  414.481     2.970 NaN NaN  SPEAKER_00 NaN NaN\n",
       "84  SPEAKER  싼기타_비싼기타     1  417.755     3.476 NaN NaN  SPEAKER_01 NaN NaN\n",
       "85  SPEAKER  싼기타_비싼기타     1  423.644     0.776 NaN NaN  SPEAKER_00 NaN NaN\n",
       "86  SPEAKER  싼기타_비싼기타     1  424.741     3.527 NaN NaN  SPEAKER_00 NaN NaN\n",
       "87  SPEAKER  싼기타_비싼기타     1  428.504     0.844 NaN NaN  SPEAKER_00 NaN NaN\n",
       "\n",
       "[88 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "rttm_path= \"./audio/싼기타_비싼기타.rttm\"\n",
    "\n",
    "df_rttm = pd.read_csv(\n",
    "    rttm_path,\n",
    "    sep=' ',\n",
    "    header=None,\n",
    "    names=['type', 'file', 'chnl','start', 'duration', 'C1', 'C2', 'speaker_id', 'C3', 'C4']\n",
    ")\n",
    "\n",
    "display(df_rttm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc7c3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>file</th>\n",
       "      <th>chnl</th>\n",
       "      <th>start</th>\n",
       "      <th>duration</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993</td>\n",
       "      <td>5.805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>7.405</td>\n",
       "      <td>3.983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>11.759</td>\n",
       "      <td>4.927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>17.210</td>\n",
       "      <td>10.665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>28.668</td>\n",
       "      <td>1.536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>414.481</td>\n",
       "      <td>2.970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>417.755</td>\n",
       "      <td>3.476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>421.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>423.644</td>\n",
       "      <td>0.776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>424.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>424.741</td>\n",
       "      <td>3.527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>428.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>싼기타_비싼기타</td>\n",
       "      <td>1</td>\n",
       "      <td>428.504</td>\n",
       "      <td>0.844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>429.348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       type      file  chnl    start  duration  C1  C2  speaker_id  C3  C4  \\\n",
       "0   SPEAKER  싼기타_비싼기타     1    0.993     5.805 NaN NaN  SPEAKER_01 NaN NaN   \n",
       "1   SPEAKER  싼기타_비싼기타     1    7.405     3.983 NaN NaN  SPEAKER_01 NaN NaN   \n",
       "2   SPEAKER  싼기타_비싼기타     1   11.759     4.927 NaN NaN  SPEAKER_01 NaN NaN   \n",
       "3   SPEAKER  싼기타_비싼기타     1   17.210    10.665 NaN NaN  SPEAKER_01 NaN NaN   \n",
       "4   SPEAKER  싼기타_비싼기타     1   28.668     1.536 NaN NaN  SPEAKER_01 NaN NaN   \n",
       "..      ...       ...   ...      ...       ...  ..  ..         ...  ..  ..   \n",
       "83  SPEAKER  싼기타_비싼기타     1  414.481     2.970 NaN NaN  SPEAKER_00 NaN NaN   \n",
       "84  SPEAKER  싼기타_비싼기타     1  417.755     3.476 NaN NaN  SPEAKER_01 NaN NaN   \n",
       "85  SPEAKER  싼기타_비싼기타     1  423.644     0.776 NaN NaN  SPEAKER_00 NaN NaN   \n",
       "86  SPEAKER  싼기타_비싼기타     1  424.741     3.527 NaN NaN  SPEAKER_00 NaN NaN   \n",
       "87  SPEAKER  싼기타_비싼기타     1  428.504     0.844 NaN NaN  SPEAKER_00 NaN NaN   \n",
       "\n",
       "        end  \n",
       "0     6.798  \n",
       "1    11.388  \n",
       "2    16.686  \n",
       "3    27.875  \n",
       "4    30.204  \n",
       "..      ...  \n",
       "83  417.451  \n",
       "84  421.231  \n",
       "85  424.420  \n",
       "86  428.268  \n",
       "87  429.348  \n",
       "\n",
       "[88 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start + durationd을 end로 변환\n",
    "df_rttm['end'] = df_rttm['start'] + df_rttm['duration']\n",
    "\n",
    "display(df_rttm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae0484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rttm[\"number\"] = None\t# number 열 만들고 None으로 초기화\n",
    "df_rttm.at[0, \"number\"] = 0\n",
    "\n",
    "display(df_rttm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c85672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(df_rttm)):\n",
    "    if df_rttm.at[i, \"speaker_id\"] != df_rttm.at[i-1, \"speaker_id\"]:\n",
    "        df_rttm.at[i, \"number\"] = df_rttm.at[i-1, \"number\"] + 1\n",
    "    else:\n",
    "        df_rttm.at[i, \"number\"] = df_rttm.at[i-1, \"number\"]\n",
    "\n",
    "display(df_rttm.head(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593334ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rttm_grouped = df_rttm.groupby(\"number\").agg(\n",
    "    start=pd.NamedAgg(column='start', aggfunc='min'),\n",
    "    end=pd.NamedAgg(column='end', aggfunc='max'),\n",
    "    speaker_id=pd.NamedAgg(column='speaker_id', aggfunc='first')\n",
    ")\n",
    "\n",
    "display(df_rttm_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659c3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rttm_grouped[\"duration\"] = df_rttm_grouped[\"end\"] - df_rttm_grouped[\"start\"]\n",
    "df_rttm_grouped = df_rttm_grouped.reset_index(drop=True)\n",
    "display(df_rttm_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rttm_grouped.to_csv(\n",
    "    \"싼기타_비싼기타_rttm.csv\",\n",
    "    sep=',',\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
